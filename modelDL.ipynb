{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94e9fdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit in c:\\users\\nh\\anaconda3\\lib\\site-packages (2023.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\nh\\anaconda3\\lib\\site-packages (from rdkit) (1.21.6)\n",
      "Requirement already satisfied: Pillow in c:\\users\\nh\\anaconda3\\lib\\site-packages (from rdkit) (9.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nh\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nh\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nh\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nh\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nh\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\nh\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26f3e704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import PandasTools, AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eb0849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae82adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef443c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "PandasTools.AddMoleculeColumnToFrame(train,'SMILES','Molecule')\n",
    "PandasTools.AddMoleculeColumnToFrame(test,'SMILES','Molecule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b9661a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol2fp(mol):\n",
    "    fp = AllChem.GetHashedMorganFingerprint(mol, 6, nBits=4096)\n",
    "    ar = np.zeros((1,), dtype=np.int8)\n",
    "    DataStructs.ConvertToNumpyArray(fp, ar)\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d4d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FPs column 추가\n",
    "train[\"FPs\"] = train.Molecule.apply(mol2fp)\n",
    "test[\"FPs\"] = test.Molecule.apply(mol2fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5017145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 column만 추출\n",
    "train = train[['FPs','MLM', 'HLM']]\n",
    "test = test[['FPs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6294e000",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, target, transform, is_test=False):\n",
    "        self.df = df\n",
    "        self.target = target # HLM or MLM\n",
    "        self.is_test = is_test # train,valid / test\n",
    "\n",
    "        self.feature_select = transform\n",
    "        if not self.is_test: \n",
    "            self.fp = self.feature_select.fit_transform(np.stack(df['FPs']))\n",
    "        else: # valid or test\n",
    "            self.fp = self.feature_select.transform(np.stack(df['FPs']))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fp = self.fp[index]\n",
    "        if not self.is_test: # test가 아닌 경우(label 존재)\n",
    "            label = self.df[self.target][index]\n",
    "            return torch.tensor(fp).float(), torch.tensor(label).float().unsqueeze(dim=-1) # feature, label\n",
    "\n",
    "        else: # test인 경우\n",
    "            return torch.tensor(fp).float() # feature\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e916100",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = VarianceThreshold(threshold=0.05).fit_transform(np.stack(train['FPs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49175441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "                              ...                        \n",
       "3493    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3494    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3495    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3496    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...\n",
       "3497    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: FPs, Length: 3498, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['FPs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "229980a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import umap\n",
    "transform = umap.UMAP(n_components = 256)\n",
    "\n",
    "train_MLM = CustomDataset(df=train, target='MLM', transform=transform, is_test=False)\n",
    "train_HLM = CustomDataset(df=train, target='HLM', transform=transform, is_test=False)\n",
    "\n",
    "input_size = train_MLM.fp.shape[1]\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4e15272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "CFG = {'BATCH_SIZE': 256,\n",
    "       'EPOCHS': 100,\n",
    "       'INPUT_SIZE': input_size,\n",
    "       'HIDDEN_SIZE': 1024,\n",
    "       'OUTPUT_SIZE': 1,\n",
    "       'DROPOUT_RATE': 0.8,\n",
    "       'LEARNING_RATE': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6966bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train,valid split\n",
    "train_MLM_dataset, valid_MLM_dataset = train_test_split(train_MLM, test_size=0.2, random_state=42)\n",
    "train_HLM_dataset, valid_HLM_dataset = train_test_split(train_HLM, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a721cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MLM_loader = DataLoader(dataset=train_MLM_dataset,\n",
    "                              batch_size=CFG['BATCH_SIZE'],\n",
    "                              shuffle=True)\n",
    "\n",
    "valid_MLM_loader = DataLoader(dataset=valid_MLM_dataset,\n",
    "                              batch_size=CFG['BATCH_SIZE'],\n",
    "                              shuffle=False)\n",
    "\n",
    "\n",
    "train_HLM_loader = DataLoader(dataset=train_HLM_dataset,\n",
    "                              batch_size=CFG['BATCH_SIZE'],\n",
    "                              shuffle=True)\n",
    "\n",
    "valid_HLM_loader = DataLoader(dataset=valid_HLM_dataset,\n",
    "                              batch_size=CFG['BATCH_SIZE'],\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2807655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_rate, out_size):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # fc 레이어 3개와 출력 레이어\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_out = nn.Linear(hidden_size, out_size)\n",
    "        \n",
    "        # 정규화\n",
    "        self.ln1 = nn.LayerNorm(hidden_size)\n",
    "        self.ln2 = nn.LayerNorm(hidden_size)\n",
    "        self.ln3 = nn.LayerNorm(hidden_size)        \n",
    "        \n",
    "        # 활성화 함수\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "     \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.ln1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        out = self.ln2(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc3(out)\n",
    "        out = self.ln3(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0d2fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MLM = Net(CFG['INPUT_SIZE'],CFG['HIDDEN_SIZE'],CFG['DROPOUT_RATE'],CFG['OUTPUT_SIZE'])\n",
    "model_HLM = Net(CFG['INPUT_SIZE'],CFG['HIDDEN_SIZE'],CFG['DROPOUT_RATE'],CFG['OUTPUT_SIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5333888",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer_MLM = torch.optim.Adam(model_MLM.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "optimizer_HLM = torch.optim.Adam(model_HLM.parameters(), lr=CFG['LEARNING_RATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec3a73ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, valid_loader, model, criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            valid_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in valid_loader:\n",
    "                    output = model(inputs)\n",
    "                    loss = criterion(output, targets)\n",
    "                    valid_loss += loss.item()\n",
    "                    \n",
    "            print(f'Epoch: {epoch}/{epochs}, Train Loss: {running_loss/len(train_loader)}, Valid Loss: {valid_loss/len(valid_HLM_loader)}')\n",
    "            \n",
    "            model.train()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4bdf4229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start: MLM\n",
      "Epoch: 0/100, Train Loss: 2092.469082919034, Valid Loss: 1900.72998046875\n",
      "Training Start: HLM\n",
      "Epoch: 0/100, Train Loss: 3231.7992942116475, Valid Loss: 2640.923095703125\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Start: MLM\")\n",
    "model_MLM = train(train_MLM_loader, valid_MLM_loader, model_MLM, criterion, optimizer_MLM, epochs=CFG['EPOCHS'])\n",
    "\n",
    "print(\"Training Start: HLM\")\n",
    "model_HLM = train(train_HLM_loader, valid_HLM_loader, model_HLM, criterion, optimizer_HLM, epochs=CFG['EPOCHS'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96adf687",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_MLM = CustomDataset(df=test, target=None, transform=transform, is_test=True)\n",
    "test_HLM = CustomDataset(df=test, target=None, transform=transform, is_test=True)\n",
    "\n",
    "test_MLM_loader = DataLoader(dataset=test_MLM,\n",
    "                             batch_size=CFG['BATCH_SIZE'],\n",
    "                             shuffle=False)\n",
    "\n",
    "test_HLM_loader = DataLoader(dataset=test_HLM,\n",
    "                             batch_size=CFG['BATCH_SIZE'],\n",
    "                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db324d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(test_loader, model):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs in test_loader:\n",
    "            output = model(inputs)\n",
    "            preds.extend(output.cpu().numpy().flatten().tolist())\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "126531ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_MLM = inference(test_MLM_loader, model_MLM)\n",
    "predictions_HLM = inference(test_HLM_loader, model_HLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a86133f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MLM</th>\n",
       "      <th>HLM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>TEST_478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>TEST_479</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>TEST_480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>TEST_481</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>TEST_482</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  MLM  HLM\n",
       "0    TEST_000    0    0\n",
       "1    TEST_001    0    0\n",
       "2    TEST_002    0    0\n",
       "3    TEST_003    0    0\n",
       "4    TEST_004    0    0\n",
       "..        ...  ...  ...\n",
       "478  TEST_478    0    0\n",
       "479  TEST_479    0    0\n",
       "480  TEST_480    0    0\n",
       "481  TEST_481    0    0\n",
       "482  TEST_482    0    0\n",
       "\n",
       "[483 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b41c6d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MLM</th>\n",
       "      <th>HLM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>6.269782</td>\n",
       "      <td>33.620461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>67.026260</td>\n",
       "      <td>85.984589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>18.682957</td>\n",
       "      <td>70.903282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>46.637009</td>\n",
       "      <td>64.868774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>14.306131</td>\n",
       "      <td>85.060646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>TEST_478</td>\n",
       "      <td>29.508043</td>\n",
       "      <td>75.322456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>TEST_479</td>\n",
       "      <td>84.376472</td>\n",
       "      <td>86.260284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>TEST_480</td>\n",
       "      <td>8.017731</td>\n",
       "      <td>85.646698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>TEST_481</td>\n",
       "      <td>27.685152</td>\n",
       "      <td>76.680557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>TEST_482</td>\n",
       "      <td>9.946722</td>\n",
       "      <td>85.327805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        MLM        HLM\n",
       "0    TEST_000   6.269782  33.620461\n",
       "1    TEST_001  67.026260  85.984589\n",
       "2    TEST_002  18.682957  70.903282\n",
       "3    TEST_003  46.637009  64.868774\n",
       "4    TEST_004  14.306131  85.060646\n",
       "..        ...        ...        ...\n",
       "478  TEST_478  29.508043  75.322456\n",
       "479  TEST_479  84.376472  86.260284\n",
       "480  TEST_480   8.017731  85.646698\n",
       "481  TEST_481  27.685152  76.680557\n",
       "482  TEST_482   9.946722  85.327805\n",
       "\n",
       "[483 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['MLM'] = predictions_MLM\n",
    "submission['HLM'] = predictions_HLM\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6523a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('data/DL_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "145c16cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "add22569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 column만 추출\n",
    "train_X = train[[ 'AlogP',\n",
    " 'Molecular_Weight',\n",
    " 'Num_H_Acceptors',\n",
    " 'Num_H_Donors',\n",
    " 'Num_RotatableBonds',\n",
    " 'LogD',\n",
    " 'Molecular_PolarSurfaceArea']]\n",
    "\n",
    "train_MLM = train['MLM']\n",
    "\n",
    "train_HLM = train['HLM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a332e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test[[ 'AlogP',\n",
    " 'Molecular_Weight',\n",
    " 'Num_H_Acceptors',\n",
    " 'Num_H_Donors',\n",
    " 'Num_RotatableBonds',\n",
    " 'LogD',\n",
    " 'Molecular_PolarSurfaceArea']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d008e83",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgboost' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7bddd4c41a5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxgb_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'xgboost' is not defined"
     ]
    }
   ],
   "source": [
    "xgb_model = xgboost.XGBRegressor(n_estimators = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e67f7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(train_X,train_MLM)\n",
    "predictionsMLM = xgb_model.predict(test_X)\n",
    "\n",
    "xgb_model.fit(train_X,train_HLM)\n",
    "predictionsHLM = xgb_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8fa9dcb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "37458210",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eaf13cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['MLM'] = (submission['MLM'] + predictionsMLM) / 2\n",
    "submission['HLM'] = (submission['HLM'] + predictionsHLM) / 2\n",
    "submission.to_csv('data/baselineWithXGBoost_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65bab6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
